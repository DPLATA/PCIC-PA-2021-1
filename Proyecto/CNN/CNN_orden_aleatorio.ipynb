{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bulgarian-guyana",
   "metadata": {},
   "source": [
    "### Paquetes empleados para el desarrollo de la modelación con julia de Redes convolucionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "packed-lincoln",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "--2021-02-08 17:02:06--  https://pkg.julialang.org/registry/23338594-aafe-5451-b93e-139f81909106/54662d38fc61a7d9de148125e91e907e29b36302\n",
      "Resolving pkg.julialang.org (pkg.julialang.org)... 2a04:4e42:c::729, 151.101.50.217\n",
      "Connecting to pkg.julialang.org (pkg.julialang.org)|2a04:4e42:c::729|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 ipv6 us-east internal redirect trigger\n",
      "Location: https://us-east.pkg.julialang.org/registry/23338594-aafe-5451-b93e-139f81909106/54662d38fc61a7d9de148125e91e907e29b36302 [following]\n",
      "--2021-02-08 17:02:06--  https://us-east.pkg.julialang.org/registry/23338594-aafe-5451-b93e-139f81909106/54662d38fc61a7d9de148125e91e907e29b36302\n",
      "Resolving us-east.pkg.julialang.org (us-east.pkg.julialang.org)... 2600:1f18:18bc:3800:8d39:de54:21e4:22d5, 54.144.24.222\n",
      "Connecting to us-east.pkg.julialang.org (us-east.pkg.julialang.org)|2600:1f18:18bc:3800:8d39:de54:21e4:22d5|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2718519 (2.6M) [application/octet-stream]\n",
      "Saving to: ‘/tmp/jl_xS1xC1-download.gz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  1%  710K 4s\n",
      "    50K .......... .......... .......... .......... ..........  3%  699K 4s\n",
      "   100K .......... .......... .......... .......... ..........  5% 7.25M 2s\n",
      "   150K .......... .......... .......... .......... ..........  7%  920K 2s\n",
      "   200K .......... .......... .......... .......... ..........  9% 1.83M 2s\n",
      "   250K .......... .......... .......... .......... .......... 11% 2.35M 2s\n",
      "   300K .......... .......... .......... .......... .......... 13% 50.9M 2s\n",
      "   350K .......... .......... .......... .......... .......... 15% 3.81M 1s\n",
      "   400K .......... .......... .......... .......... .......... 16%  736K 2s\n",
      "   450K .......... .......... .......... .......... .......... 18% 7.85M 1s\n",
      "   500K .......... .......... .......... .......... .......... 20% 7.50M 1s\n",
      "   550K .......... .......... .......... .......... .......... 22% 2.76M 1s\n",
      "   600K .......... .......... .......... .......... .......... 24% 7.57M 1s\n",
      "   650K .......... .......... .......... .......... .......... 26% 3.91M 1s\n",
      "   700K .......... .......... .......... .......... .......... 28% 1.47M 1s\n",
      "   750K .......... .......... .......... .......... .......... 30% 9.17M 1s\n",
      "   800K .......... .......... .......... .......... .......... 32% 7.23M 1s\n",
      "   850K .......... .......... .......... .......... .......... 33% 6.98M 1s\n",
      "   900K .......... .......... .......... .......... .......... 35% 6.64M 1s\n",
      "   950K .......... .......... .......... .......... .......... 37% 6.08M 1s\n",
      "  1000K .......... .......... .......... .......... .......... 39% 5.71M 1s\n",
      "  1050K .......... .......... .......... .......... .......... 41% 5.45M 1s\n",
      "  1100K .......... .......... .......... .......... .......... 43% 2.69M 1s\n",
      "  1150K .......... .......... .......... .......... .......... 45% 1.67M 1s\n",
      "  1200K .......... .......... .......... .......... .......... 47% 14.2M 1s\n",
      "  1250K .......... .......... .......... .......... .......... 48% 9.32M 1s\n",
      "  1300K .......... .......... .......... .......... .......... 50% 3.85M 1s\n",
      "  1350K .......... .......... .......... .......... .......... 52% 11.1M 0s\n",
      "  1400K .......... .......... .......... .......... .......... 54% 6.07M 0s\n",
      "  1450K .......... .......... .......... .......... .......... 56% 4.75M 0s\n",
      "  1500K .......... .......... .......... .......... .......... 58% 10.0M 0s\n",
      "  1550K .......... .......... .......... .......... .......... 60% 3.14M 0s\n",
      "  1600K .......... .......... .......... .......... .......... 62% 7.82M 0s\n",
      "  1650K .......... .......... .......... .......... .......... 64% 5.63M 0s\n",
      "  1700K .......... .......... .......... .......... .......... 65% 7.20M 0s\n",
      "  1750K .......... .......... .......... .......... .......... 67% 4.74M 0s\n",
      "  1800K .......... .......... .......... .......... .......... 69% 7.82M 0s\n",
      "  1850K .......... .......... .......... .......... .......... 71% 5.19M 0s\n",
      "  1900K .......... .......... .......... .......... .......... 73% 3.04M 0s\n",
      "  1950K .......... .......... .......... .......... .......... 75% 15.8M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 77% 7.42M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 79% 4.46M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 80% 7.44M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 82% 5.14M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 84% 3.73M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 86% 6.16M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 88% 5.29M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 90% 4.52M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 92% 7.98M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 94% 6.88M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 96% 6.46M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 97% 7.77M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 99% 4.43M 0s\n",
      "  2650K ....                                                  100% 9162G=0.8s\n",
      "\n",
      "2021-02-08 17:02:07 (3.42 MB/s) - ‘/tmp/jl_xS1xC1-download.gz’ saved [2718519/2718519]\n",
      "\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Project.toml`\n",
      "\u001b[32m\u001b[1mNo Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.5/Manifest.toml`\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "The following package names could not be resolved:\n * ImagenView (not found in project, manifest or registry)\n",
     "output_type": "error",
     "traceback": [
      "The following package names could not be resolved:\n * ImagenView (not found in project, manifest or registry)\n",
      "",
      "Stacktrace:",
      " [1] pkgerror(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:52",
      " [2] ensure_resolved(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; registry::Bool) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/Types.jl:837",
      " [3] add(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}; preserve::Pkg.Types.PreserveLevel, platform::Pkg.BinaryPlatforms.Linux, kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:177",
      " [4] add(::Pkg.Types.Context, ::Array{Pkg.Types.PackageSpec,1}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:139",
      " [5] #add#21 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:67 [inlined]",
      " [6] add at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:67 [inlined]",
      " [7] #add#20 at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:66 [inlined]",
      " [8] add at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:66 [inlined]",
      " [9] add(::String; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:65",
      " [10] add(::String) at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Pkg/src/API.jl:65",
      " [11] top-level scope at In[148]:5",
      " [12] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "# Pkg.add(\"Flux\")\n",
    "Pkg.add(Pkg.PackageSpec(;name=\"Flux\", version=\"0.9.0\"))\n",
    "Pkg.add(\"BSON\")\n",
    "Pkg.add(\"ImagenView\")\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add(\"ImageIO\")\n",
    "Pkg.add(\"ImageMagick\")\n",
    "Pkg.add(\"Tracker\")\n",
    "Pkg.add(\"Images\")\n",
    "Pkg.add(\"FileIO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "inclusive-budget",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/arteck/Documents/P/maestria/tareas/1_semestre/Programación Avanzada\n"
     ]
    }
   ],
   "source": [
    "; pwd #Validación de en que carpeta nos encontramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "exclusive-interstate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Viola-Jones' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "; git clone https://github.com/INVASIS/Viola-Jones ## utilizamos este repo para cargar las fotos de cara, no cara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "expired-warrant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCN.ipynb\n",
      "RCN_orden_aleatorio.ipynb\n",
      "RCN_sin_desordenar.ipynb\n",
      "Viola-Jones\n",
      "yalefaces\n"
     ]
    }
   ],
   "source": [
    "; ls # Validamos que se creo la carpeta \"Viola-Jones\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "automotive-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON\n",
    "using ImageView\n",
    "using Plots\n",
    "using Tracker\n",
    "##Use \n",
    "using Images, FileIO\n",
    "using Random: shuffle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "lovely-serbia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.240639 seconds (628.63 k allocations: 33.522 MiB)\n",
      "  0.816508 seconds (2.21 M allocations: 118.425 MiB, 1.94% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10977-element Array{Float64,1}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time begin\n",
    "    files_faces_train = readdir(\"Viola-Jones/data/trainset/faces/\")  # Se obtienen las imagenes de caras para el entrenamiento\n",
    "    images_train = Array{Array{Gray{Normed{UInt8,8}},2},1}() # Se crea un arreglo que permita almacenar las imagens normalizadas y en escala de grises para el entrenamiento\n",
    "    for file in files_faces_train # Recorremos el arreglo con las imágenes precentes en files_faces_train\n",
    "        img_path = \"Viola-Jones/data/trainset/faces/\" * file # Se crea el path de la imágen a cargar\n",
    "        img_temp = load(img_path) # Se carga la imagen\n",
    "        push!(images_train, img_temp)    #Se agrega la imagen a images_train\n",
    "    end\n",
    "end\n",
    "y_train=ones(size(files_faces_train)) #Arreglo con la etiqueta de face = 1, no face = 0, iniciando con las imagenes de face, es decir, 1\n",
    "@time begin\n",
    "    files_no_faces_train = readdir(\"Viola-Jones/data/trainset/non-faces/\") # Se obtienen las imagenes de no caras para el entrenamiento\n",
    "    for file in files_no_faces_train # Recorremos el arreglo con las imágenes precentes en files_no_faces_train\n",
    "        img_path = \"Viola-Jones/data/trainset/non-faces/\" * file # Se crea el path de la imágen a cargar\n",
    "        img_temp = load(img_path) # Se carga la imagen\n",
    "        push!(images_train, img_temp)    #Se agrega la imagen a images_train\n",
    "    end\n",
    "end\n",
    "y_train = vcat(y_train, zeros(size(files_no_faces_train))) #Agregar los datos de las no faces, es decir, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "worth-scotland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.049838 seconds (121.80 k allocations: 6.501 MiB)\n",
      "  1.905780 seconds (5.07 M allocations: 270.585 MiB, 2.56% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20044-element Array{Float64,1}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time begin\n",
    "    files_faces_test = readdir(\"Viola-Jones/data/testset/faces/\") # Se obtienen las imagenes de caras para la validación\n",
    "    images_test = Array{Array{Gray{Normed{UInt8,8}},2},1}() # Se crea un arreglo que permita almacenar las imagens normalizadas y en escala de grises para la validación\n",
    "    for file in files_faces_test # Recorremos el arreglo con las imágenes precentes en files_faces_test\n",
    "        img_path = \"Viola-Jones/data/testset/faces/\" * file # Se crea el path de la imágen a cargar\n",
    "        img_temp = load(img_path) # Se carga la imagen\n",
    "        push!(images_test, img_temp)     #Se agrega la imagen a images_test\n",
    "    end\n",
    "end\n",
    "y_test=ones(size(files_faces_test)) #Arreglo con la etiqueta de face = 1, no face = 0, iniciando con las imagenes de face, es decir, 1\n",
    "@time begin\n",
    "    files_no_faces_test = readdir(\"Viola-Jones/data/testset/non-faces/\") # Se obtienen las imagenes de no caras para la validación\n",
    "    for file in files_no_faces_test # Recorremos el arreglo con las imágenes precentes en files_no_faces_test\n",
    "        img_path = \"Viola-Jones/data/testset/non-faces/\" * file # Se crea el path de la imágen a cargar\n",
    "        img_temp = load(img_path) # Se carga la imagen\n",
    "        push!(images_test, img_temp)     #Se agrega la imagen a images_test\n",
    "    end\n",
    "end\n",
    "y_test = vcat(y_test, zeros(size(files_no_faces_test))) #Agregar los datos de las no faces, es decir, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "responsible-following",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10977-element Array{Int64,1}:\n",
       "  1126\n",
       "  1829\n",
       "  8488\n",
       " 10532\n",
       "  7384\n",
       "  9500\n",
       "  8028\n",
       "  2006\n",
       "  1552\n",
       "  7445\n",
       "  4026\n",
       "  6019\n",
       "  8898\n",
       "     ⋮\n",
       "   375\n",
       "  5868\n",
       "  3937\n",
       "  7487\n",
       "  5667\n",
       "  3535\n",
       "  5246\n",
       "  3669\n",
       "  5783\n",
       "  6939\n",
       "  6051\n",
       "  5311"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index =shuffle(1: length(y_train)) ## En el notebook RCN_sin_desordenar.ipynb se incluian las imagenes\n",
    "### sin un nuevo ordenamiento aleatorio, para que el batch que se cree contenga caras y no caras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "modular-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Se crean las variables necesarias para seguir el tutorial de https://towardsdatascience.com/a-primer-on-computer-vision-with-julia-2c7068a35b32\n",
    "train_labels = gpu.(y_train[index])\n",
    "train_imgs = gpu.(images_train[index]);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "spiritual-title",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20044-element Array{Float64,1}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " ⋮\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0\n",
       " 0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### para el test\n",
    "test_imgs = images_test\n",
    "test_labels = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "returning-collection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de dataset de entrenamiento es de: (10977,) \n",
      "El tamaño de dataset de validación es de: (20044,)"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"El tamaño de dataset de entrenamiento es de: $(size(train_imgs)) \\n\")\n",
    "print(\"El tamaño de dataset de validación es de: $(size(test_imgs))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "mounted-telephone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 19)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(train_imgs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "motivated-million",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHIAAAByCAAAAACqttqhAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAANFSURBVGje7dtLj1VFFAXgr+2DgtjaCFFQUTRRRkw0xhnRgYmJP9Y/wMSpI1+JmEhMi6hRedlt0zZoO1jsZBOH5HqSc6sGnXPrtXqfrLtq1a66Gx+BD8Hb4DR4DhwDx8EGOAKb4H6rOQT7YK/V/Amugx/AE/73MiCXAzm9iWLm7+BncBKcAufAM+BJcND6PEDx+bC17rWYnkdxez1e7IBcUZmin9HGb1FM+yXN4EXwDngLxdW/wC7YAV+Aa6hvQUrYvjlXlANyOZDTbyhGPYXyA6nPmr7Tnr8Hr6A0807rn7+/ttmi0tHhg7miHJDLgZzCpXsoXxr9PNdqorpxC9fa4DD2WbCNYv6rKN1OOZg3ygG5HMgp/MyeKy40a/ePqHU/inobfINi5h8on7AN/mmtV1HM3wI35opyQC4Hcgq7oqVZx6OH4eoJVK4gz++Dj8EnKO09an0226i42XwvXporygG5HMgpe6uoZc9Thb3Zc4WB4fB7KDaeAXdROYT0vNVmS+vJFt96vNgBuaIybbUP2VuFw1nNo5lPg79RHjXPZ8HXKFeQscdbTfi/0eJbjxc7IFdUpqzaYWbYm13YdvuPkvVKdisuIir6AornyQ+83sZmtuzawuH7c0U5IJcDOcW1hoFZ5eMHss+KW4jGXsCjniHr/mVwpbW+gUd9bOpvzhXlgFwO5BSWZtWO5wwPo4dZ/S+hVDQKnMzVd63mZdRp7FeovG6c7al5oxyQy4F8mN0KY6OlUdes9WHaZ6gz3DiBnBTcaP3jFi7+ByC3FPItGCcIA/Kxy8MThGhpeJtT17A3CvkTKov1OUqBH7Q++21UZov2vobKFRzOFeWAXA7klFPX7Pqz/woPP0X5hNQctuf0DG/D1fjVL1ufqOuZFtnuXFEOyOVATslNhXv9htX1Vr/VWsPMZF/vtomSrY2XOGhjz7easfMakI9dpjAtN1cvoLxrbiH221bbKL/aXUR4G8+QE4cocD/tOmr91+PFDsgVlY0P2od3UWcEYV1caDgZbvebMzkv2G014XPUODcT9lvrzlxRDsjlQE7Z6Yd78bRZzZNTTZ42ipoVPxnanAsca/0zw2br03+PsNdmW48XOyBXVP4FoOC2Rr2zMi8AAAAASUVORK5CYII=",
      "text/plain": [
       "19×19 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.282)  Gray{N0f8}(0.553)  …  Gray{N0f8}(0.514)\n",
       " Gray{N0f8}(0.427)  Gray{N0f8}(0.573)     Gray{N0f8}(0.627)\n",
       " Gray{N0f8}(0.459)  Gray{N0f8}(0.533)     Gray{N0f8}(0.471)\n",
       " Gray{N0f8}(0.376)  Gray{N0f8}(0.506)     Gray{N0f8}(0.427)\n",
       " Gray{N0f8}(0.361)  Gray{N0f8}(0.471)     Gray{N0f8}(0.412)\n",
       " Gray{N0f8}(0.404)  Gray{N0f8}(0.667)  …  Gray{N0f8}(0.49)\n",
       " Gray{N0f8}(0.451)  Gray{N0f8}(0.647)     Gray{N0f8}(0.592)\n",
       " Gray{N0f8}(0.467)  Gray{N0f8}(0.592)     Gray{N0f8}(0.6)\n",
       " Gray{N0f8}(0.518)  Gray{N0f8}(0.592)     Gray{N0f8}(0.608)\n",
       " Gray{N0f8}(0.537)  Gray{N0f8}(0.627)     Gray{N0f8}(0.624)\n",
       " Gray{N0f8}(0.506)  Gray{N0f8}(0.557)  …  Gray{N0f8}(0.545)\n",
       " Gray{N0f8}(0.584)  Gray{N0f8}(0.588)     Gray{N0f8}(0.545)\n",
       " Gray{N0f8}(0.627)  Gray{N0f8}(0.631)     Gray{N0f8}(0.514)\n",
       " Gray{N0f8}(0.612)  Gray{N0f8}(0.6)       Gray{N0f8}(0.439)\n",
       " Gray{N0f8}(0.482)  Gray{N0f8}(0.576)     Gray{N0f8}(0.376)\n",
       " Gray{N0f8}(0.31)   Gray{N0f8}(0.463)  …  Gray{N0f8}(0.353)\n",
       " Gray{N0f8}(0.282)  Gray{N0f8}(0.345)     Gray{N0f8}(0.357)\n",
       " Gray{N0f8}(0.255)  Gray{N0f8}(0.255)     Gray{N0f8}(0.341)\n",
       " Gray{N0f8}(0.188)  Gray{N0f8}(0.204)     Gray{N0f8}(0.271)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Se vizualiza una imagen de 19 x 19 pixeles\n",
    "NROWS, NCOLS = 19, 19\n",
    "a = reshape(train_imgs[1], NROWS, NCOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "verified-methodology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "800/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "environmental-northeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    \n",
    "    #Primera convoluciona, recibe un canal (1 => 16) y crea diferentes resultados de la imagen\n",
    "    #Aplicando un filtro de 3x3, se considera un zero padding de 2, es decir a los pixeles, se le agrega\n",
    "    ## 2 pixiles de 0 para lograr incorporar inforamción de las orillas de la imange, la función de\n",
    "    ## Activación es Relu, es un rectificador lineal que ayuda a quitar la linealidad\n",
    "    ## de entrenaer el modelo esto se repetirá en la capa siguiente\n",
    "    Conv((3, 3), 1=>16, pad=(2,2), relu),\n",
    "    MaxPool((2,2)), #maxpooling\n",
    "    ## Para reducir el tamaño de las matrices finales de utilza un muestro, en este caso, cada cuatro \n",
    "    ## Pixeles se seleccionará el máximo (maxpolling)\n",
    "\n",
    "    # Se repite el caso anterior, pero en esta ocación el número de canales de entrada es de 16,\n",
    "    # y el zero padding sólo considera 1 pixel extra, se utiliza de nuevo la función de activación \n",
    "    # Relu\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)), #maxpooling\n",
    "\n",
    "    # En el tutorial seguido sugieren agregar otra capa de convolución, por ser de pixeles \n",
    "#     Conv((3, 3), 32=>32,pad=(1,1), relu),\n",
    "#     MaxPool((2,2)),\n",
    "    # Hasta este punto tenemos un arreglo de (5,5,32, 2)\n",
    "    #Entonces se hace un reshape de la salida con una capa de salida (Dense)\n",
    "    #la cual tendrá una entra de 800 y salida de 2\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    \n",
    "    Dense(800, 2),\n",
    "    # Se agrega una capa softmax para obtener las probabilidades\n",
    "    softmax,\n",
    ")\n",
    "\n",
    "model = gpu(model); # Flux nos permite cargar el modelo en gpu en caso de contar con \n",
    "# hardware y controladores necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "deluxe-client",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching \n",
    "# See: https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl\n",
    "# Bundle images together with labels and group into minibatchess\n",
    "function make_minibatch(X, Y, idxs)\n",
    "    ### Se usa la sigueinte función para crear los barch que se usarán en el entrenamiento del modelo\n",
    "    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] = Float32.(X[idxs[i]])\n",
    "    end\n",
    "    #onehotbatch permite crear un encoder que es válido para la red neuronal convoluconal\n",
    "    Y_batch = onehotbatch(Y[idxs], 0:1)\n",
    "    return (X_batch, Y_batch)\n",
    "end\n",
    "# La red sólo verá 128 imágenes a la vez:\n",
    "batch_size = 128\n",
    "# Se crea una partición con 128 elementos en cada Pi\n",
    "mb_idxs = partition(1:length(train_imgs), batch_size)\n",
    "# Se desconpone train_imgs para que contenga minibatch de 128\n",
    "train_set = [make_minibatch(train_imgs, train_labels, i) for i in mb_idxs];\n",
    "# de tiene el resultado pero para toda la información de train\n",
    "train_set_full = make_minibatch(train_imgs, train_labels, 1:length(train_imgs));\n",
    "# Se desconpone test_imgs para que contenga minibatch de 128\n",
    "test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "discrete-sister",
   "metadata": {},
   "outputs": [],
   "source": [
    "Creamos la función de perdida\n",
    "function loss(x, y)\n",
    "    ## Se agrega un poco de ruido a la imagen para evitar sobre ajuste\n",
    "    x_aug = x .+ 0.1f0*gpu(randn(eltype(x), size(x)))\n",
    "\n",
    "    y_hat = model(x_aug)\n",
    "    # Se calcula la función de pérdida usando crossentropy\n",
    "    return crossentropy(y_hat, y)\n",
    "end\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "\n",
    "# El optimizador que se usa para entrenar la red es ADAM\n",
    "opt = ADAM(0.001);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "preliminary-listening",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: [1]: Train accuracy: 0.9818\n",
      "└ @ Main In[115]:14\n",
      "┌ Info: [1]: Test accuracy: 0.9730\n",
      "└ @ Main In[115]:18\n",
      "┌ Info:  -> Early-exiting: We reached our target accuracy of 97.0%\n",
      "└ @ Main In[115]:22\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "# See: https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "accuracy_target = 0.97 #Set an accuracy target. When reached, we stop training.\n",
    "max_epochs = 100 #Máximas iteraciones\n",
    "for epoch_idx in 1:100\n",
    "    \n",
    "    global best_acc, last_improvement\n",
    "    # Entrenamiento para un sólo batch\n",
    "    Flux.train!(loss, params(model), train_set, opt)\n",
    "\n",
    "    # Calculo de la exactitud\n",
    "    acc = accuracy(train_set_full...)\n",
    "    @info(@sprintf(\"[%d]: Train accuracy: %.4f\", epoch_idx, acc))\n",
    "    \n",
    "    # Calculo de la exactitud\n",
    "    acc = accuracy(test_set...)\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch_idx, acc))\n",
    "\n",
    "    # En caso de tener una exactitud mayor a la de accuracy_target se sale del ciclo\n",
    "    if acc >= accuracy_target\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of $(accuracy_target*100)%\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # En caso de tener una exactitud mayor a la de accuracy_target se sale del ciclo\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "divine-minimum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×20044 Array{Int64,2}:\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  …  0  0  0  0  0  0  0  0  0  0  0  0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get predictions and convert data to Array: \n",
    "pred = Tracker.data(model(test_set[1])); \n",
    "\n",
    "# Function to get the row index of the max value: \n",
    "f1(x) = getindex.(argmax(x, dims=1), 1) # Final predicted value is the one with the maximum probability: \n",
    "pred = f1(pred) .- 1; #minus 1, because the first digit is 0 (not 1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-cooking",
   "metadata": {},
   "source": [
    "### Métricas de desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "pending-armor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positives = sum((y_test .== transpose(pred)) .& (y_test .== 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "little-mining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19428"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_negatives = sum((y_test .== transpose(pred)) .& (y_test .== 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "missing-interview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives = sum((y_test .!= transpose(pred)) .& (y_test .== 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "automotive-anatomy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives = sum((y_test .!= transpose(pred)) .& (y_test .== 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-camel",
   "metadata": {},
   "source": [
    "### Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "athletic-particular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3424657534246575"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acurracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "impressive-florida",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La exactitud del modelo fue: 0.9730093793653961\n",
      "La precisión del modelo fue: 0.15889830508474576\n",
      "El recall del modelo fue: 0.3424657534246575\n"
     ]
    }
   ],
   "source": [
    "print(\"La exactitud del modelo fue: $(acurracy)\\n\")\n",
    "print(\"La precisión del modelo fue: $(precision)\\n\")\n",
    "print(\"El recall del modelo fue: $(recall)\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-sociology",
   "metadata": {},
   "source": [
    "# Bibliografía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.juanbarrios.com/redes-neurales-convolucionales/#:~:text=Capa%20De%20Convoluci%C3%B3n%3A%20procesar%C3%A1%20la,en%20el%20volumen%20de%20entrada.\n",
    "https://medium.com/@jayeshbahire/cnn-implementation-using-julia-defe90d86eb2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
